{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "srXC6pLGLwS6"
   },
   "source": [
    "# Trabajo final — Generación de música clásica con RNN\n",
    "## Ander Aguinaga San Sebastián — MAIS 3.º A\n",
    "#### 2023/01/16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "WGyKZj3bzf9p"
   },
   "source": [
    "### Importamos las librerías necesarias\n",
    "Para lo relacionado con el modelo, necesitamos importar Tensorflow, Keras y Numpy, como de costumbre. Utilizamos también la librería `glob` para acceder, como veremos a continuación, a ficheros dentro de una carpeta. Por último, la librería `music21` nos ayudará a manejar ficheros MIDI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:08.261025Z",
     "iopub.status.busy": "2022-05-03T11:14:08.260828Z",
     "iopub.status.idle": "2022-05-03T11:14:10.284556Z",
     "shell.execute_reply": "2022-05-03T11:14:10.283846Z"
    },
    "id": "yG_n40gFzf9s"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation\n",
    "from keras import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import glob\n",
    "\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "\n",
    "print(\"Número de GPU disponibles: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "EHDoRoc5PKWz"
   },
   "source": [
    "### Importamos los datos\n",
    "Los datos son notas y acordes que leeremos de los archivos `.mid` que tengamos en nuestra carpeta de datos de entrenamiento. De cada uno de estos archivos, extraeremos los elementos de tipo `note.Note` o `chord.Chord` (de `music21`) que encontremos (hay más objetos además de esos, como la clave o la fórmula de compás, pero estos no nos interesan para lo que queremos hacer). Los guardaremos como cadenas de texto que contienen de forma legible la nota que tienen asociada (las notas se dan separadas por punto en el caso de los acordes). Por ejemplo, si en el MIDI se encuentra un la central, se añadirá al _array_ `notes` la cadena _A4_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(folder):\n",
    "    notes = []\n",
    "    for file in glob.glob(folder + \"/*\"):\n",
    "        midi = converter.parse(file)\n",
    "        notes_to_parse = midi.flat.notes\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "    global n_vocab\n",
    "    global pitches\n",
    "    pitches = sorted(set(notes))\n",
    "    n_vocab = len(pitches)\n",
    "    return notes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "UHjdCjDuSvX_"
   },
   "source": [
    "### Preparamos las secuencias\n",
    "\n",
    "La idea es entrenar nuestro modelo dándole como _input_ una secuencia de notas o acordes, y generando como _output_ un _array_ que nos dirá la probabilidad de que la siguiente nota o acorde sea una dada. El _input_ estará normalizado para asegurar la mayor eficacia posible en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes):\n",
    "    sequence_length = 100\n",
    "    # get all pitch names\n",
    "    global pitches\n",
    "    pitches = sorted(set(notes))\n",
    "\n",
    "    # create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitches))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "    \n",
    "    n_patterns = len(network_input)\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "\n",
    "    return network_input, network_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definimos la arquitectura de la red\n",
    "\n",
    "Será una red neuronal recurrente (RNN), con varias capas LSTM que ayudarán a encontrar patrones en los datos. El motivo de utilizar tantas capas `Dropout` es que queremos eviatar el _overfitting_, propenso a aparecer en este tipo de situaciones. El modelo acaba con una capa densa de `n_vocab`, el número de notas y acordes distintos, que sería el equivalente al tamaño del abecedario en un modelo de generación de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(network_input):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        256,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(512, return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(256))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparamos el modelo\n",
    "Compilamos utilizando `categorical_crossentropy` como función _loss_, pues es un problema de tipo categórico, y el optimizador RMS Prop, que es el que mejor ha funcionado según las pruebas que he estado haciendo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model(network_input):\n",
    "    model = create_model(network_input)\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamos el modelo\n",
    "Al entrenar, guardamos los pesos de cada época en que el _loss_ haya disminuido en comparación a la época anterior, de esta forma siempre podremos recuperar los pesos de las mejores épocas sin necesidad de gastar memoria almacenando los pesos de absolutamente todas ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, network_input, network_output, epochs, batch_size, filepath = \"weights/e-{epoch:02d}-l-{loss:.4f}.hdf5\"):\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath, monitor='loss', \n",
    "        verbose=0,        \n",
    "        save_best_only=True,        \n",
    "        mode='min'\n",
    "    )    \n",
    "    callbacks_list = [checkpoint]     \n",
    "    model.fit(network_input, network_output, epochs=epochs, batch_size=batch_size, callbacks=callbacks_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generamos notas\n",
    "Primero tomamos al azar una de las secuencias de notas que habíamos preparado antes para el entrenamiento, y la guardamos en `pattern`. Partiendo de ahí, comenzamos a predecir las notas siguientes, y utilizando las nuevas notas generadas en la secuencia _input_ para la siguiente predicción. Ya que el modelo predice un _array_ de probabilidades, la nota que nos interesa corresponde al índice de la probabilidad más alta.\n",
    "\n",
    "Con esta función acabamos generando un array de _strings_ que contienen el nombre de la nota, como hemos visto antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes(model, network_input, num_notes):\n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitches))\n",
    "    pattern = network_input[start]*n_vocab\n",
    "    prediction_output = []\n",
    "    \n",
    "    for note_index in range(num_notes):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "        index = np.argmax(prediction)\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "        pattern = np.append(pattern, index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "    \n",
    "    return prediction_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generamos el MIDI\n",
    "Convertimos las notas generadas a objetos de `music21` que van a poder ser exportados a un fichero MIDI. Si se ha generado un acorde, se extrae al MIDI una nota para cada una de las que había en el acorde, sin modificar el _offset_ para que se escuchen a la vez. Si se ha generado una nota, se extrae esa nota al MIDI, a no ser que coincida con la anterior, en cuyo caso se actualizará el _offset_ sin extraer una nota nueva. De esta forma, se da la sensación de que la duración de las notas varía, en lugar de escuchar notas repetidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi(filename, prediction_output):\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    last_pattern = None\n",
    "    for pattern in prediction_output:\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # pattern is a note\n",
    "        elif(last_pattern != pattern):\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "        last_pattern = pattern\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "    \n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp=filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función simplemente se encarga de llamar a las dos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_midi(model, network_input, num_notes, filename = \"output.mid\"):\n",
    "    prediction_output = generate_notes(model, network_input, num_notes)\n",
    "    print(prediction_output)\n",
    "    create_midi(filename, prediction_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llamamos a las funciones\n",
    "Ya que todo el código que hemos visto estaba en funciones aisladas, ahora solo debemos llamarlas en orden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = import_data(\"bach1\")\n",
    "network_input, network_output = prepare_sequences(notes)\n",
    "model = prepare_model(network_input)\n",
    "model.load_weights('weightsBach.hdf5')\n",
    "#train_model(model, network_input, network_output, 20, 64)\n",
    "generate_midi(model, network_input, 500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "En un principio quise intentar generar música de forma algo más sofisticada, tomando en cuenta también la duración de las notas, cosa que en este proyecto no he hecho. Complicaba bastante las cosas, y creo que es mejor empezar con algo más simple, y avanzar a eso más complejo con más tiempo en un futuro. Además, como expliqué arriba, evitando insertar dos notas iguales una detrás de otra, he acabado dando el efecto de que sí varía la duración, aunque internamente no sea del todo así.\n",
    "\n",
    "No sé exactamente cómo interpretar los resultados, pues han ocurrido todo tipo de cosas. He probado con dos tres conjuntos de datos: dos con piezas de Bach y uno con piezas de Debussy.\n",
    "\n",
    "Cuando entreno con piezas de Debussy (carpeta _debussy_), la música generada suele ser monótona y con muchos acordes. La obra de Debussy es impresionista, y por su naturaleza, además de tener muchos más acordes, creo que es más difícil de predecir. Por eso, la mejor solución que encuentra el modelo es acabar reproduciendo en bucle un mismo acorde (_debussy1.mid_).\n",
    "\n",
    "Bach es de estilo barroco, sus preludios y fugas tienen mucho contrapunto, son piezas más _calculadas_, más _matemáticas_, y en ese sentido puede hacérsele más fácil a una IA generar música así.\n",
    "\n",
    "El primer conjunto de datos de Bach (carpeta _bach1_) tenía tres MIDIs, cada uno conteniendo un preludio y una fuga. Pensé que sería un conjunto de datos provisional, pues tenía pensado buscar más MIDIs y hacer un entrenamiento mejor. Los resultados fueron bastante positivos: aunque a veces se note el _overfitting_ porque genera música demasiado similar a las piezas originales (_bach2.mid_ se parece mucho al preludio V), en general reproduce algo escuchable (_bach1.mid_), que a veces parece algo aleatorio, pero por lo menos tiene más movimiento que con Debussy, donde se quedaba estancado.\n",
    "\n",
    "El segundo conjunto de datos de Bach (carpeta _bach2_) tenía 19 MIDIs, cada uno conteniendo un preludio o una fuga. Para mi sorpresa, obtuve resultados peores, se quedaba estancado muchísimo más: como con Debussy, pero sin tantos acordes. Es cierto que no se notan copias descaradas, pero reproduce una pieza final monótona y que nadie querría escuchar (_bach3.mid_). Además, si seguía entrenándolo, incluso sin llegar a tantos entrenamientos que con el _dataset_ anterior, ya se quedaba completamente estancado y producida MIDIs de una única nota (_bach4.mid_).\n",
    "\n",
    "También probé con distintas arquitecturas de red, modificando el ratio de _dropout_, quitando capas _LSTM_, modificando el número de neuronas, etc., y al mínimo cambio acababa obteniendo resultados considerablemente peores, que producían notas estancadas.\n",
    "\n",
    "En definitiva, ¡he obtenido resultados peores cada vez que intentaba mejorar lo que tenía! Pero he aprendido mucho trabajando en ello. :)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_generation.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a4b831d8046030f06c4e1eda3c51cd4515b11159e253f3c0059ed00cc8ec9b9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
